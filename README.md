# Checkpoint 02 - Machine Learning em Energias RenovÃ¡veis

## ğŸ‘¥ Integrante
- Renan Mano Otero - RM 554911

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este repositÃ³rio contÃ©m a implementaÃ§Ã£o completa do Checkpoint 02 da disciplina **SoluÃ§Ãµes em Energias RenovÃ¡veis e SustentÃ¡veis**. O projeto aplica tÃ©cnicas de Machine Learning (regressÃ£o e classificaÃ§Ã£o) em datasets relacionados a energia solar, eÃ³lica, consumo residencial e estabilidade de redes elÃ©tricas.

## ğŸ—‚ï¸ Estrutura do RepositÃ³rio

```
checkpoint02-ml-energia/
â”‚
â”œâ”€â”€ data/                          # Datasets
â”‚   â”œâ”€â”€ appliances/
â”‚   â”‚   â””â”€â”€ energydata_complete.csv
â”‚   â”œâ”€â”€ smart_grid/
â”‚   â”‚   â””â”€â”€ smart_grid_stability.csv
â”‚   â”œâ”€â”€ solar/
â”‚   â”‚   â””â”€â”€ SolarPrediction.csv
â”‚   â””â”€â”€ wind/
â”‚       â””â”€â”€ wind_turbine_scada.csv
â”‚
â”œâ”€â”€ notebooks/                     # Notebooks Jupyter
â”‚   â””â”€â”€ CP02_completo.ipynb       # Notebook principal com todas as anÃ¡lises
â”‚
â”œâ”€â”€ orange/                        # Workflows Orange Data Mining
â”‚   â”œâ”€â”€ CP02_001_regressao_appliances.ows
â”‚   â”œâ”€â”€ CP02_001_classificacao_smartgrid.ows
â”‚   â”œâ”€â”€ CP02_002_classificacao_solar.ows
â”‚   â””â”€â”€ CP02_002_regressao_wind.ows
â”‚
â”œâ”€â”€ requirements.txt               # DependÃªncias Python
â”œâ”€â”€ .gitignore                     # Arquivos ignorados pelo Git
â””â”€â”€ README.md                      # Este arquivo
```

## ğŸ“Š Datasets Utilizados

### 1. Appliances Energy Prediction
- **Fonte**: UCI Machine Learning Repository
- **DescriÃ§Ã£o**: Dados de consumo de energia de eletrodomÃ©sticos com variÃ¡veis ambientais
- **Tarefa**: RegressÃ£o
- **Split**: 70/30

### 2. Smart Grid Stability
- **Fonte**: UCI / Kaggle
- **DescriÃ§Ã£o**: Dados simulados de estabilidade de rede elÃ©trica
- **Tarefa**: ClassificaÃ§Ã£o (EstÃ¡vel/InstÃ¡vel)
- **Split**: 70/30

### 3. Solar Radiation Prediction
- **Fonte**: [Kaggle - Solar Energy Dataset](https://www.kaggle.com/datasets/dronio/SolarEnergy)
- **DescriÃ§Ã£o**: PrevisÃ£o de radiaÃ§Ã£o solar baseada em condiÃ§Ãµes climÃ¡ticas
- **Tarefa**: ClassificaÃ§Ã£o (Alta/Baixa radiaÃ§Ã£o pela mediana)
- **Split**: 70/30

### 4. Wind Turbine SCADA
- **Fonte**: [Kaggle - Wind Turbine Dataset](https://www.kaggle.com/datasets/berkerisen/wind-turbine-scada-dataset)
- **DescriÃ§Ã£o**: Dados operacionais de turbinas eÃ³licas
- **Tarefa**: RegressÃ£o (Prever potÃªncia gerada em kW)
- **Split**: 80/20

## ğŸš€ Como Executar

### PrÃ©-requisitos

- Python 3.8+
- Jupyter Notebook ou Google Colab
- Git

### InstalaÃ§Ã£o Local

```bash
# Clonar o repositÃ³rio
git clone https://github.com/idrenanbr/checkpoint02-ml-energia.git
cd checkpoint02-ml-energia

# Instalar dependÃªncias
pip install -r requirements.txt

# Iniciar Jupyter Notebook
jupyter notebook
```

### Executar no Google Colab

1. Acesse o [Google Colab](https://colab.research.google.com/)
2. FaÃ§a upload do notebook `CP02_completo.ipynb`
3. FaÃ§a upload dos datasets na sessÃ£o do Colab
4. Execute: Runtime â†’ Run all

## ğŸ“ˆ Resultados Obtidos

### âœ… Parte 1 - RegressÃ£o: Appliances Energy Prediction

**Objetivo**: Prever consumo de energia de eletrodomÃ©sticos

**Modelos Testados**:
- RegressÃ£o Linear
- Decision Tree Regressor
- Random Forest Regressor

**Resultados**:

| Modelo | RÂ² | RMSE | MAE |
|--------|-----|------|-----|
| **Random Forest** | **0.537** | **68.04** | **32.60** |
| Decision Tree | 0.180 | 90.60 | 38.87 |
| Linear Regression | 0.169 | 91.17 | 52.55 |

**Melhor Modelo**: Random Forest Regressor
- **RÂ²**: 0.537 - O modelo explica 53.7% da variÃ¢ncia dos dados
- **RMSE**: 68.04 Wh - Erro mÃ©dio de previsÃ£o
- **MAE**: 32.60 Wh - Erro absoluto mÃ©dio

**AnÃ¡lise**: O Random Forest superou os outros modelos devido Ã  sua capacidade de capturar relaÃ§Ãµes nÃ£o-lineares entre as variÃ¡veis ambientais e o consumo de energia.

---

### âœ… Parte 2 - ClassificaÃ§Ã£o: Smart Grid Stability

**Objetivo**: Classificar estabilidade da rede elÃ©trica (EstÃ¡vel/InstÃ¡vel)

**Modelos Testados**:
- Decision Tree Classifier
- K-Nearest Neighbors (KNN)
- Logistic Regression

**Resultados**:

| Modelo | AcurÃ¡cia | F1-Score |
|--------|----------|----------|
| **Decision Tree** | **1.000** | **1.000** |
| Logistic Regression | 0.9995 | 0.9995 |
| KNN | 0.818 | 0.816 |

**Melhor Modelo**: Decision Tree Classifier
- **AcurÃ¡cia**: 100% - ClassificaÃ§Ã£o perfeita
- **F1-Score**: 1.000 - EquilÃ­brio perfeito entre precisÃ£o e recall
- **Matriz de ConfusÃ£o**: 6522 verdadeiros negativos, 11478 verdadeiros positivos, 0 erros

**AnÃ¡lise**: O Decision Tree alcanÃ§ou desempenho perfeito, sugerindo que os dados possuem padrÃµes bem definidos para classificaÃ§Ã£o de estabilidade. A Logistic Regression tambÃ©m apresentou excelente desempenho (99.95%), enquanto o KNN teve performance inferior devido Ã  sensibilidade a dados de alta dimensionalidade.

---

### âœ… ExercÃ­cio 1 - ClassificaÃ§Ã£o: Solar Radiation

**Objetivo**: Classificar perÃ­odos de Alta/Baixa radiaÃ§Ã£o solar

**Modelos Testados**:
- Decision Tree Classifier
- Random Forest Classifier
- Support Vector Machine (SVM)

**ConfiguraÃ§Ã£o**:
- Split: 70/30 (treino/teste)
- NormalizaÃ§Ã£o: StandardScaler aplicado
- Alvo: Criado pela mediana da radiaÃ§Ã£o solar

**Resultados**:

| Modelo | AcurÃ¡cia |
|--------|----------|
| **Random Forest** | **98.01%** |
| Decision Tree | 97.20% |
| SVM | 95.66% |

**Melhor Modelo**: Random Forest Classifier
- **AcurÃ¡cia**: 98.01% - Excelente capacidade de classificaÃ§Ã£o
- **CaracterÃ­sticas**: Ensemble de Ã¡rvores que reduz overfitting e melhora generalizaÃ§Ã£o

**AnÃ¡lise**: O Random Forest obteve o melhor desempenho ao combinar mÃºltiplas Ã¡rvores de decisÃ£o, capturando melhor as relaÃ§Ãµes complexas entre variÃ¡veis meteorolÃ³gicas e radiaÃ§Ã£o solar. O SVM, mesmo com normalizaÃ§Ã£o, teve desempenho ligeiramente inferior, possivelmente devido Ã  nÃ£o-linearidade dos dados.

---

### âœ… ExercÃ­cio 2 - RegressÃ£o: Wind Turbine Power

**Objetivo**: Prever potÃªncia gerada por turbina eÃ³lica (kW)

**Modelos Testados**:
- Linear Regression
- Decision Tree Regressor
- Random Forest Regressor

**ConfiguraÃ§Ã£o**:
- Split: 80/20 (treino/teste)
- VariÃ¡vel alvo: LV ActivePower (kW)

**Resultados**:

| Modelo | RÂ² | RMSE |
|--------|-----|------|
| **Linear Regression** | **0.901** | **411.71** |
| Random Forest | 0.900 | 412.36 |
| Decision Tree | 0.830 | 538.79 |

**Melhor Modelo**: Linear Regression
- **RÂ²**: 0.901 - O modelo explica 90.1% da variÃ¢ncia dos dados
- **RMSE**: 411.71 kW - Erro mÃ©dio de previsÃ£o

**AnÃ¡lise**: Surpreendentemente, a RegressÃ£o Linear teve o melhor desempenho, indicando que a relaÃ§Ã£o entre velocidade do vento e potÃªncia gerada Ã© aproximadamente linear (ou jÃ¡ bem capturada pela potÃªncia teÃ³rica). O Random Forest teve desempenho muito similar (RÂ² = 0.900), enquanto a Decision Tree individual sofreu com overfitting.

---

## ğŸ¯ Principais Aprendizados

1. **DiferenciaÃ§Ã£o entre RegressÃ£o e ClassificaÃ§Ã£o**: 
   - RegressÃ£o para valores contÃ­nuos (energia, potÃªncia)
   - ClassificaÃ§Ã£o para categorias discretas (estÃ¡vel/instÃ¡vel, alta/baixa radiaÃ§Ã£o)

2. **ImportÃ¢ncia da NormalizaÃ§Ã£o**: 
   - Crucial para algoritmos baseados em distÃ¢ncia (KNN, SVM)
   - Menos relevante para modelos baseados em Ã¡rvores

3. **Ensemble Methods (Random Forest)**:
   - Geralmente superam modelos Ãºnicos
   - Reduzem overfitting atravÃ©s da agregaÃ§Ã£o de mÃºltiplos modelos

4. **Contexto dos Dados**:
   - Modelos simples (Linear Regression) podem ser suficientes quando relaÃ§Ãµes sÃ£o lineares
   - Modelos complexos (Random Forest) brilham em relaÃ§Ãµes nÃ£o-lineares

5. **MÃ©tricas Apropriadas**:
   - RÂ² e RMSE para regressÃ£o avaliam capacidade de previsÃ£o numÃ©rica
   - AcurÃ¡cia, F1-score e matriz de confusÃ£o para classificaÃ§Ã£o avaliam capacidade de discriminaÃ§Ã£o entre classes

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.8+**
- **Pandas** - ManipulaÃ§Ã£o de dados
- **NumPy** - ComputaÃ§Ã£o numÃ©rica
- **Scikit-learn** - Algoritmos de ML
- **Matplotlib/Seaborn** - VisualizaÃ§Ã£o
- **Jupyter Notebook / Google Colab** - Ambiente de desenvolvimento
- **Orange Data Mining** - Workflows visuais

## ğŸ“ ObservaÃ§Ãµes

- Os notebooks incluem geraÃ§Ã£o de dados sintÃ©ticos como fallback quando os CSVs reais nÃ£o estÃ£o disponÃ­veis
- Para resultados autÃªnticos, utilize os datasets originais baixados dos links fornecidos
- Os workflows Orange (arquivos .ows) requerem ajuste manual dos caminhos dos arquivos
- Todos os modelos usam `random_state=42` para garantir reprodutibilidade

## ğŸ”— Links Ãšteis

- [DocumentaÃ§Ã£o Scikit-learn](https://scikit-learn.org/)
- [Orange Data Mining](https://orangedatamining.com/)
- [Kaggle Datasets](https://www.kaggle.com/datasets)
- [UCI ML Repository](https://archive.ics.uci.edu/)

## ğŸ“§ Contato

**Renan Mano Otero**  
RM: 554911  
GitHub: [@idrenanbr](https://github.com/idrenanbr)

---

**Disciplina**: SoluÃ§Ãµes em Energias RenovÃ¡veis e SustentÃ¡veis  
**Professor**: AndrÃ© Tritiack  
**Data de Entrega**: 24 de setembro de 2025
