{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51daa024",
   "metadata": {},
   "source": [
    "\n",
    "# Casos de Uso de Machine Learning – Energia Solar e Eólica\n",
    "\n",
    "Este notebook contém a resolução das tarefas propostas na disciplina **Soluções em Energias Renováveis e Sustentáveis**.  O objetivo é aplicar algoritmos de regressão e classificação a diferentes conjuntos de dados relacionados a energia, comparando modelos e discutindo os resultados obtidos.\n",
    "\n",
    "As atividades estão divididas em quatro blocos:\n",
    "\n",
    "1. **Parte 1 – Regressão (Appliances Energy Prediction)**: prever o consumo de eletrodomésticos a partir de variáveis ambientais.\n",
    "2. **Parte 2 – Classificação (Smart Grid Stability)**: classificar se a rede elétrica está estável ou instável com base em medições elétricas.\n",
    "3. **Exercício 1 – Classificação (Solar)**: classificar períodos de alta ou baixa radiação solar a partir de dados meteorológicos.\n",
    "4. **Exercício 2 – Regressão (Eólica)**: prever a potência gerada por uma turbina eólica utilizando medidas de vento e potência teórica.\n",
    "\n",
    "> **Nota:** sempre que os arquivos CSV reais não estiverem disponíveis, dados sintéticos são gerados para fins de demonstração.  Para reproduzir os resultados com os datasets originais, copie os arquivos correspondentes para a pasta `data/` indicada no README e ajuste os nomes se necessário.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcee814",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79279532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Funções auxiliares para avaliação e carregamento de dados\n",
    "\n",
    "def evaluate_regression(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    mae = mean_absolute_error(y_test, preds)\n",
    "    return {\"R²\": r2, \"RMSE\": rmse, \"MAE\": mae}\n",
    "\n",
    "\n",
    "def evaluate_classification(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "    pos_label = y_test.unique()[0] if hasattr(y_test, 'unique') else 1\n",
    "    prec = precision_score(y_test, preds, average='binary', pos_label=pos_label)\n",
    "    rec = recall_score(y_test, preds, average='binary', pos_label=pos_label)\n",
    "    f1 = f1_score(y_test, preds, average='binary', pos_label=pos_label)\n",
    "    cm = confusion_matrix(y_test, preds)\n",
    "    return {\"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1, \"Confusion Matrix\": cm}\n",
    "\n",
    "\n",
    "def load_dataset(path, synthetic_generator):\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        return df, False\n",
    "    else:\n",
    "        print(f\"Arquivo {path} não encontrado. Usando dados sintéticos para demonstração.\")\n",
    "        X, y = synthetic_generator()\n",
    "        return pd.concat([X, y], axis=1), True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ca0de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Geradores de dados sintéticos\n",
    "\n",
    "def synthetic_appliances_data(n_samples=2000, random_state=42):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    temps = rng.uniform(10, 30, size=(n_samples, 5))\n",
    "    humidity = rng.uniform(20, 90, size=(n_samples, 5))\n",
    "    pressure = rng.uniform(990, 1030, size=(n_samples, 1))\n",
    "    windspeed = rng.uniform(0, 10, size=(n_samples, 1))\n",
    "    coeffs = np.array([3.5, -1.2, 4.0, 2.1, -0.8] + [-0.5, 0.3, -1.1, 0.7, 0.5] + [0.02] + [-1.5])\n",
    "    features = np.hstack([temps, humidity, pressure, windspeed])\n",
    "    noise = rng.normal(0, 5, size=n_samples)\n",
    "    y = features.dot(coeffs) + noise\n",
    "    cols = [f\"temp_{i+1}\" for i in range(5)] + [f\"hum_{i+1}\" for i in range(5)] + [\"pressure\", \"windspeed\"]\n",
    "    X = pd.DataFrame(features, columns=cols)\n",
    "    y = pd.Series(y, name=\"Appliances\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def synthetic_smart_grid_data(n_samples=2000, random_state=42):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    features = rng.uniform(-1, 1, size=(n_samples, 4))\n",
    "    linear = features.dot(np.array([1.0, -1.2, 0.8, -0.5])) + rng.normal(0, 0.2, size=n_samples)\n",
    "    y = (linear > 0).astype(int)\n",
    "    X = pd.DataFrame(features, columns=[\"P_active\", \"P_reactive\", \"Voltage\", \"Current\"])\n",
    "    y = pd.Series(y, name=\"Stability\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def synthetic_solar_data(n_samples=1500, random_state=42):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    temperature = rng.uniform(15, 40, n_samples)\n",
    "    humidity = rng.uniform(10, 90, n_samples)\n",
    "    pressure = rng.uniform(950, 1030, n_samples)\n",
    "    wind = rng.uniform(0, 10, n_samples)\n",
    "    clouds = rng.uniform(0, 100, n_samples)\n",
    "    radiation = 0.02 * temperature - 0.01 * humidity + 0.03 * wind + rng.normal(0, 0.5, n_samples)\n",
    "    median_rad = np.median(radiation)\n",
    "    y = (radiation >= median_rad).astype(int)\n",
    "    X = pd.DataFrame({\n",
    "        \"Temperature\": temperature,\n",
    "        \"Humidity\": humidity,\n",
    "        \"Pressure\": pressure,\n",
    "        \"WindSpeed\": wind,\n",
    "        \"CloudCoverage\": clouds,\n",
    "    })\n",
    "    y = pd.Series(y, name=\"HighRadiation\")\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def synthetic_wind_data(n_samples=1500, random_state=42):\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    wind_speed = rng.uniform(0, 25, n_samples)\n",
    "    wind_direction = rng.uniform(0, 360, n_samples)\n",
    "    theoretical_power = 0.5 * wind_speed ** 3\n",
    "    efficiency = rng.uniform(0.2, 0.45, n_samples)\n",
    "    active_power = theoretical_power * efficiency + rng.normal(0, 50, n_samples)\n",
    "    X = pd.DataFrame({\n",
    "        \"WindSpeed\": wind_speed,\n",
    "        \"WindDirection\": wind_direction,\n",
    "        \"TheoreticalPower\": theoretical_power,\n",
    "    })\n",
    "    y = pd.Series(active_power, name=\"LVActivePower\")\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57ef5b6",
   "metadata": {},
   "source": [
    "\n",
    "## Parte 1 – Regressão: Previsão de consumo de eletrodomésticos\n",
    "\n",
    "O objetivo desta seção é prever o consumo de energia (Wh) de uma residência a partir de variáveis ambientais coletadas ao longo de 4,5 meses.  Os dados originais, descritos no [repositório da UCI](https://archive.ics.uci.edu/dataset/374/appliances+energy+prediction), incluem temperatura, umidade e condições climáticas externas registradas em intervalos de 10 minutos 【722290714644327†L46-L54】.  Como os valores nem sempre estão disponíveis em todas as máquinas, o código abaixo tenta carregar o arquivo `energydata_complete.csv` na pasta `data/`; caso não exista, um conjunto sintético é gerado para demonstração.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141f2021",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parte 1: carregar dataset de appliances\n",
    "df_appliances, synthetic_flag = load_dataset('data/energydata_complete.csv', synthetic_appliances_data)\n",
    "\n",
    "# Preparar features e alvo\n",
    "if not synthetic_flag:\n",
    "    df_appliances['date'] = pd.to_datetime(df_appliances['date'])\n",
    "    df_appliances['hour'] = df_appliances['date'].dt.hour\n",
    "    df_appliances['dayofweek'] = df_appliances['date'].dt.dayofweek\n",
    "    feature_cols = [col for col in df_appliances.columns if col not in ['date', 'Appliances']]\n",
    "    X_appliances = df_appliances[feature_cols]\n",
    "    y_appliances = df_appliances['Appliances']\n",
    "else:\n",
    "    X_appliances = df_appliances.drop(columns=['Appliances'])\n",
    "    y_appliances = df_appliances['Appliances']\n",
    "\n",
    "# Dividir em treino e teste\n",
    "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(X_appliances, y_appliances, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalizar\n",
    "scaler_a = StandardScaler()\n",
    "X_train_a_scaled = scaler_a.fit_transform(X_train_a)\n",
    "X_test_a_scaled = scaler_a.transform(X_test_a)\n",
    "\n",
    "# Definir modelos\n",
    "regressors = {\n",
    "    'Regressão Linear': LinearRegression(),\n",
    "    'Árvore de Regressão': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42, n_estimators=200)\n",
    "}\n",
    "\n",
    "results_reg = {}\n",
    "for name, model in regressors.items():\n",
    "    metrics = evaluate_regression(model, X_train_a_scaled, y_train_a, X_test_a_scaled, y_test_a)\n",
    "    results_reg[name] = metrics\n",
    "\n",
    "# Mostrar resultados\n",
    "pd.DataFrame(results_reg).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b426668",
   "metadata": {},
   "source": [
    "\n",
    "**Discussão:**\n",
    "\n",
    "O quadro acima resume o desempenho de três modelos de regressão.  A Regressão Linear serve como baseline e assume uma relação linear entre as variáveis ambientais e o consumo de energia.  A Árvore de Regressão captura relações não lineares simples, enquanto a Random Forest, composta por várias árvores, tende a modelar interações complexas e reduzir o overfitting.  Em geral, espera‑se que a Random Forest apresente maior R² e menor RMSE/MAE devido à sua capacidade de generalizar melhor.  Entretanto, a diferença real só pode ser avaliada com os dados originais; os dados sintéticos aqui servem apenas para ilustrar a metodologia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098d288a",
   "metadata": {},
   "source": [
    "\n",
    "## Parte 2 – Classificação: Estabilidade de rede elétrica inteligente\n",
    "\n",
    "Nesta seção utilizamos um dataset de estabilidade de rede (não público) para treinar modelos que classifiquem se a rede está **estável** ou **instável** a partir de medidas elétricas como potência ativa, potência reativa, tensão e corrente.  Como os dados podem não estar disponíveis, o código tenta ler `smart_grid_stability.csv` na pasta `data/` e, caso não exista, gera um dataset sintético.  Os algoritmos avaliados são uma Árvore de Decisão, KNN e Regressão Logística.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c279b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parte 2: carregar dataset de estabilidade\n",
    "df_grid, synthetic_flag_grid = load_dataset('data/smart_grid_stability.csv', synthetic_smart_grid_data)\n",
    "\n",
    "if not synthetic_flag_grid:\n",
    "    target_col = [col for col in df_grid.columns if col.lower().startswith('stab')][0]\n",
    "    X_grid = df_grid.drop(columns=[target_col])\n",
    "    y_grid = df_grid[target_col]\n",
    "else:\n",
    "    X_grid = df_grid.drop(columns=['Stability'])\n",
    "    y_grid = df_grid['Stability']\n",
    "\n",
    "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(X_grid, y_grid, test_size=0.3, random_state=42, stratify=y_grid)\n",
    "\n",
    "scaler_g = StandardScaler()\n",
    "X_train_g_scaled = scaler_g.fit_transform(X_train_g)\n",
    "X_test_g_scaled = scaler_g.transform(X_test_g)\n",
    "\n",
    "classifiers = {\n",
    "    'Árvore de Decisão': DecisionTreeClassifier(random_state=42),\n",
    "    'KNN (k=5)': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Regressão Logística': LogisticRegression(max_iter=1000)\n",
    "}\n",
    "\n",
    "results_clf = {}\n",
    "for name, model in classifiers.items():\n",
    "    metrics = evaluate_classification(model, X_train_g_scaled, y_train_g, X_test_g_scaled, y_test_g)\n",
    "    results_clf[name] = {k: v for k, v in metrics.items() if k != 'Confusion Matrix'}\n",
    "    results_clf[name]['Confusion Matrix'] = metrics['Confusion Matrix']\n",
    "\n",
    "# Mostrar resultados sem matriz de confusão\n",
    "pd.DataFrame({k: {metric: v for metric, v in m.items() if metric != 'Confusion Matrix'} for k, m in results_clf.items()}).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e085937",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Matrizes de confusão para cada modelo de classificação\n",
    "title_cmap = {'Árvore de Decisão': 'Blues', 'KNN (k=5)': 'Blues', 'Regressão Logística': 'Blues'}\n",
    "for name, metrics in results_clf.items():\n",
    "    cm = metrics['Confusion Matrix']\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap=title_cmap[name])\n",
    "    plt.title(f\"Matriz de Confusão – {name}\")\n",
    "    plt.xlabel(\"Predito\")\n",
    "    plt.ylabel(\"Verdadeiro\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30e086a",
   "metadata": {},
   "source": [
    "\n",
    "**Discussão:**\n",
    "\n",
    "A comparação entre os classificadores mostra como diferentes algoritmos tratam a separação entre classes.  A Árvore de Decisão é fácil de interpretar, mas pode sofrer overfitting; o KNN depende da escolha de `k` e da distância entre pontos; a Regressão Logística pressupõe uma relação linear entre as variáveis e a logit da probabilidade.  A seleção do modelo mais confiável deve considerar acurácia, recall e F1‑score, pois cada métrica enfatiza um aspecto (taxa de acertos gerais, sensibilidade a falsos negativos e equilíbrio entre precisão e recall, respectivamente).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76de9aab",
   "metadata": {},
   "source": [
    "\n",
    "## Exercício 1 – Classificação: Previsão de nível de radiação solar\n",
    "\n",
    "Aqui utilizamos o dataset de radiação solar para classificar períodos em **Alta Radiação** e **Baixa Radiação**.  A variável alvo é criada com base na mediana da radiação solar.  Caso o arquivo `SolarPrediction.csv` (ou similar) não esteja disponível, serão gerados dados sintéticos.  Os algoritmos avaliados são Árvore de Decisão, Random Forest e Support Vector Machine (SVM).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee914226",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exercício 1: carregar dataset de radiação solar\n",
    "df_solar, synthetic_flag_solar = load_dataset('data/SolarPrediction.csv', synthetic_solar_data)\n",
    "\n",
    "if not synthetic_flag_solar:\n",
    "    rad_col = [c for c in df_solar.columns if 'radiat' in c.lower() or 'solar' in c.lower()][0]\n",
    "    median_rad = df_solar[rad_col].median()\n",
    "    df_solar['HighRadiation'] = (df_solar[rad_col] >= median_rad).astype(int)\n",
    "    feature_cols = [col for col in df_solar.columns if col not in [rad_col, 'HighRadiation']]\n",
    "    X_solar = df_solar[feature_cols]\n",
    "    y_solar = df_solar['HighRadiation']\n",
    "else:\n",
    "    X_solar = df_solar.drop(columns=['HighRadiation'])\n",
    "    y_solar = df_solar['HighRadiation']\n",
    "\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_solar, y_solar, test_size=0.3, random_state=42, stratify=y_solar)\n",
    "\n",
    "scaler_s = StandardScaler()\n",
    "X_train_s_scaled = scaler_s.fit_transform(X_train_s)\n",
    "X_test_s_scaled = scaler_s.transform(X_test_s)\n",
    "\n",
    "classifiers_solar = {\n",
    "    'Árvore de Decisão': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=200),\n",
    "    'SVM (linear)': SVC(kernel='linear')\n",
    "}\n",
    "\n",
    "results_solar = {}\n",
    "for name, model in classifiers_solar.items():\n",
    "    metrics = evaluate_classification(model, X_train_s_scaled, y_train_s, X_test_s_scaled, y_test_s)\n",
    "    results_solar[name] = {k: v for k, v in metrics.items() if k != 'Confusion Matrix'}\n",
    "    results_solar[name]['Confusion Matrix'] = metrics['Confusion Matrix']\n",
    "\n",
    "# Mostrar resultados\n",
    "pd.DataFrame({k: {metric: v for metric, v in m.items() if metric != 'Confusion Matrix'} for k, m in results_solar.items()}).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c41f7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Matrizes de confusão para a classificação de radiação solar\n",
    "for name, metrics in results_solar.items():\n",
    "    cm = metrics['Confusion Matrix']\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')\n",
    "    plt.title(f\"Matriz de Confusão – {name}\")\n",
    "    plt.xlabel(\"Predito\")\n",
    "    plt.ylabel(\"Verdadeiro\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80ade0a",
   "metadata": {},
   "source": [
    "\n",
    "**Discussão:**\n",
    "\n",
    "A SVM geralmente se destaca em problemas de classificação binária com fronteira bem definida, mas pode exigir mais ajustes de parâmetros (por exemplo, escolha do kernel e valor de `C`).  A Random Forest tende a apresentar boa acurácia e robustez, pois combina diversas árvores.  A Árvore de Decisão é simples e interpretável, embora possa ter desempenho inferior se houver muitas variáveis correlacionadas.  A escolha do melhor modelo deve levar em conta a acurácia, a matriz de confusão e o custo de falsos positivos/negativos no contexto de gestão de sistemas fotovoltaicos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaa9b71",
   "metadata": {},
   "source": [
    "\n",
    "## Exercício 2 – Regressão: Previsão de potência de turbinas eólicas\n",
    "\n",
    "Esta seção utiliza dados de SCADA de turbinas eólicas para prever a potência ativa gerada (kW) a partir de variáveis como velocidade do vento, direção e potência teórica.  Se o arquivo `wind_scada.csv` não estiver disponível, dados sintéticos serão gerados.  Os algoritmos avaliados são Regressão Linear, Árvore de Regressão e Random Forest Regressor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b833b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Exercício 2: carregar dataset de turbinas eólicas\n",
    "df_wind, synthetic_flag_wind = load_dataset('data/wind_scada.csv', synthetic_wind_data)\n",
    "\n",
    "if not synthetic_flag_wind:\n",
    "    target_col = [c for c in df_wind.columns if 'active' in c.lower() or ('power' in c.lower() and 'theoretical' not in c.lower())][0]\n",
    "    feature_cols = [col for col in df_wind.columns if col != target_col]\n",
    "    X_wind = df_wind[feature_cols]\n",
    "    y_wind = df_wind[target_col]\n",
    "else:\n",
    "    X_wind = df_wind.drop(columns=['LVActivePower'])\n",
    "    y_wind = df_wind['LVActivePower']\n",
    "\n",
    "X_train_w, X_test_w, y_train_w, y_test_w = train_test_split(X_wind, y_wind, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler_w = StandardScaler()\n",
    "X_train_w_scaled = scaler_w.fit_transform(X_train_w)\n",
    "X_test_w_scaled = scaler_w.transform(X_test_w)\n",
    "\n",
    "regressors_wind = {\n",
    "    'Regressão Linear': LinearRegression(),\n",
    "    'Árvore de Regressão': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42, n_estimators=200)\n",
    "}\n",
    "\n",
    "results_wind = {}\n",
    "for name, model in regressors_wind.items():\n",
    "    metrics = evaluate_regression(model, X_train_w_scaled, y_train_w, X_test_w_scaled, y_test_w)\n",
    "    results_wind[name] = metrics\n",
    "\n",
    "pd.DataFrame(results_wind).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ad449c",
   "metadata": {},
   "source": [
    "\n",
    "**Discussão:**\n",
    "\n",
    "A previsão de potência de turbinas eólicas envolve relações não lineares entre a velocidade do vento e a potência gerada.  Embora a Regressão Linear forneça um baseline, espera‑se que modelos não lineares (Árvore de Regressão e Random Forest) captem melhor a forma cúbica da curva potência × velocidade.  A Random Forest costuma oferecer melhor generalização e menor erro em comparação a uma única árvore, especialmente quando há ruído nos dados (como oscilações de vento e variações de eficiência da turbina).\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
